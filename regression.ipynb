{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from linearclassifier import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Minimizing empirical risk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Expression of optimal theta*`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# th_opt = np.dot(np.linalg.inv(X @ X.T), X @ Y.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Adding reguralization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `X@X.T` is invertible?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1, 2], [2, 3], [3, 5], [1, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5,  8, 13,  9],\n",
       "       [ 8, 13, 21, 14],\n",
       "       [13, 21, 34, 23],\n",
       "       [ 9, 14, 23, 17]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X@X.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can see that row 1 and 2 sum to row 3. So X's rows are not linearly independant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Linear regression going down"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### # In all the following definitions: x is d by n : input data y is 1 by n : output regression values th is d by 1 : weights th0 is 1 by 1 or scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin_reg(x, th, th0):\n",
    "    return np.dot(th.T, x) + th0\n",
    "\n",
    "def square_loss(x, y, th, th0):\n",
    "    return (y - lin_reg(x, th, th0))**2\n",
    "\n",
    "def mean_square_loss(x, y, th, th0):\n",
    "     # the axis=1 and keepdims=True are important when x is a full matrix\n",
    "     return np.mean(square_loss(x, y, th, th0), axis= 1, keepdims=True)\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Data set `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  x is d by n : input data\n",
    "X = np.array([[1., 2., 3., 4.], [1., 1., 1., 1.]]) \n",
    "#  y is 1 by n : output regression values\n",
    "Y = np.array([[1., 2.2, 2.8, 4.1]])\n",
    "# th is d by 1 : weights\n",
    "th = np.array([[1.0],[0.05]])\n",
    "# th0 is 1 by 1 or scalar\n",
    "th0 = np.array([[0.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient with respect to th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_lin_reg_th(x, th, th0):\n",
    "    \"\"\"RThis function returns the gradient of lin_reg with respect to th\n",
    "\n",
    "    Args:\n",
    "        x (dxn): input data , contains features on examples\n",
    "        y (1xn): output regression values\n",
    "        th (dx1): weights\n",
    "        th0 (1x1): scalar, floats linear regression line to prevent overfiting\n",
    "    \"\"\"\n",
    "    return x\n",
    "\n",
    "def d_square_loss_th(x, y, th, th0):\n",
    "    \"\"\"This function returns the gradient of lin_square_loss with respect to th. It uses lin_reg and d_lin_reg\"\"\"\n",
    "    return -2 * (y - lin_reg(x, th, th0)) * d_lin_reg_th(x, th, th0)\n",
    "\n",
    "\n",
    "def d_mean_square_loss_th(x, y, th, th0):\n",
    "    \"\"\"This function returns the gradient of mean_square_loss with respect to th. It uses d_square_loss_th.\"\"\"\n",
    "    return np.mean(d_square_loss_th(x, y, th, th0), axis=1, keepdims=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Test cases`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Test 1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans = d_lin_reg_th(X[:,0:1], th, th0)\n",
    "ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Test 2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.0, 2.0, 3.0, 4.0], [1.0, 1.0, 1.0, 1.0]]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans = d_lin_reg_th(X, th, th0).tolist()\n",
    "ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Test 3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.10000000000000009], [0.10000000000000009]]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_square_loss_th(X[:, 0:1], Y[:, 0:1], th, th0).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Test 4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.10000000000000009, -0.6000000000000014, 1.5, -0.3999999999999986],\n",
       " [0.10000000000000009, -0.3000000000000007, 0.5, -0.09999999999999964]]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_square_loss_th(X, Y, th, th0).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Test 5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.10000000000000009], [0.10000000000000009]]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_mean_square_loss_th(X[:, 0:1], Y[:, 0:1], th, th0).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Test 6`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.15000000000000002], [0.04999999999999993]]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_mean_square_loss_th(X, Y, th, th0).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient with respect to th0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_lin_reg_th0(x, th, th0):\n",
    "    \"\"\"RThis function returns the gradient of lin_reg with respect to th0\n",
    "\n",
    "    Args:\n",
    "        x (dxn): input data , contains features on examples\n",
    "        y (1xn): output regression values\n",
    "        th (dx1): weights\n",
    "        th0 (1x1): scalar, floats linear regression line to prevent overfiting\n",
    "    \"\"\"\n",
    "    return np.ones((1, x.shape[1]))\n",
    "\n",
    "def d_square_loss_th0(x, y, th, th0):\n",
    "    \"\"\"This function returns the gradient of lin_square_loss with respect to th0. It uses lin_reg and d_lin_reg_th0\"\"\"\n",
    "    return -2 * (y - lin_reg(x, th, th0)) * d_lin_reg_th0(x, th, th0)\n",
    "\n",
    "\n",
    "def d_mean_square_loss_th0(x, y, th, th0):\n",
    "    \"\"\"This function returns the gradient of mean_square_loss with respect to th. It uses d_square_loss_th0.\"\"\"\n",
    "    return np.mean(d_square_loss_th0(x, y, th, th0), axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Test case 1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.0]]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_lin_reg_th0(X[:, 0:1], th, th0).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Test 2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.0, 1.0, 1.0, 1.0]]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_lin_reg_th0(X, th, th0).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Test case 3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.10000000000000009]]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_square_loss_th0(X[:, 0:1], Y[:, 0:1], th, th0).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Test case 4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.10000000000000009, -0.3000000000000007, 0.5, -0.09999999999999964]]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_square_loss_th0(X, Y, th, th0).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Test case 5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.10000000000000009]]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_mean_square_loss_th0(X[:, 0:1], Y[:, 0:1], th, th0).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Test case 6`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.04999999999999993]]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_mean_square_loss_th0(X, Y, th, th0).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Going down the rigde"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In all the following definitions:\n",
    "# x is d by n : input data\n",
    "# y is 1 by n : output regression values\n",
    "# th is d by 1 : weights\n",
    "# th0 is 1 by 1 or scalar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rigde Objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_obj(x, y, th, th0, lam):\n",
    "    return mean_square_loss(x, y, th, th0) + lam * np.linalg.norm(th)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient og rigde objective function with respect to th and th0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_ridge_obj_th(x, y, th, th0, lam):\n",
    "    return d_mean_square_loss_th(x, y, th, th0) + 2*lam*th\n",
    "\n",
    "def d_ridge_obj_th0(x, y, th, th0, lam):\n",
    "    return d_mean_square_loss_th0(x, y, th, th0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Test 1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.12000000000000009], [0.10100000000000009]]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_ridge_obj_th(X[:, 0:1], Y[:, 0:1], th, th0, 0.01).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Test 2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.25], [0.05499999999999994]]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_ridge_obj_th(X, Y, th, th0, 0.05).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Test 3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.10000000000000009]]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_ridge_obj_th0(X[:, 0:1], Y[:, 0:1], th, th0, 0.01).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Test 4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.04999999999999993]]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_ridge_obj_th0(X, Y, th, th0, 0.05).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Stochastic gradient descent (sgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **We will implement `stochastic gradient descent` in general way as we did for gradient descent. Note that `stochastic` part refers to using a randomly selected point and corresponding label from the given dataset to perform an update.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_grad(f, delta=0.001):\n",
    "    def df(x):\n",
    "        g = np.zeros(x.shape)\n",
    "        for i in range(x.shape[0]):\n",
    "            xi = x[i, 0]\n",
    "            x[i, 0] = xi - delta\n",
    "            xm = f(x)\n",
    "            x[i, 0] = xi + delta\n",
    "            xp = f(x)\n",
    "            x[i, 0] = xi\n",
    "            g[i, 0] = (xp - xm) / (2*delta)\n",
    "        return g\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def J(Xi, yi, w):\n",
    "     # translate from (1-augmented X, y, theta) to (separated X, y, th, th0) format\n",
    "     return float(ridge_obj(Xi[:-1, :], yi, w[:-1, :], w[-1:, :], 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dJ(Xi, yi, w):\n",
    "     def f(w):\n",
    "         return J(Xi, yi, w)\n",
    "     \n",
    "     return num_grad(f)(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(X, y, J, dJ, w0, step_size_fn, max_iter):\n",
    "    n = y.shape[1]\n",
    "    prev_w = w0\n",
    "    ws = []\n",
    "    fs = []\n",
    "    np.random.seed(0)\n",
    "    for i in range(max_iter):\n",
    "        j = np.random.randint(n)\n",
    "        Xj = X[:, j:j+1]\n",
    "        yj = y[:, j:j+1]\n",
    "        prev_f = J(Xj, yj, prev_w)\n",
    "        prev_grad = dJ(Xj, yj, prev_w)\n",
    "        fs.append(prev_f)\n",
    "        ws.append(prev_w)\n",
    "        if i == max_iter - 1:\n",
    "            return prev_w, fs, ws\n",
    "        step = step_size_fn(i)\n",
    "        prev_w = prev_w - step * prev_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downwards_line():\n",
    "    X = np.array([[0.0, 0.1, 0.2, 0.3, 0.42, 0.52, 0.72, 0.78, 0.84, 1.0],\n",
    "                  [1.0, 1.0, 1.0, 1.0, 1.0,  1.0,  1.0,  1.0,  1.0,  1.0]])\n",
    "    y = np.array([[0.4, 0.6, 1.2, 0.1, 0.22, -0.6, -1.5, -0.5, -0.5, 0.0]])\n",
    "    return X, y\n",
    "\n",
    "X, y = downwards_line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.51284"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:, 0:1].shape\n",
    "#y[:, 0:1].shape\n",
    "theta = cv([0.0, 0.0])\n",
    "J(X, y, theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test cases "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def package_ans(gd_vals):\n",
    "    x, fs, xs = gd_vals\n",
    "    return [x.tolist(), [fs[0], fs[-1]], [xs[0].tolist(), xs[-1].tolist()]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Test 1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[-1.4118594928102899], [0.7705243986321614]],\n",
       " [0.36, 0.028653685126009333],\n",
       " [[[0.0], [0.0]], [[-1.4118594928102899], [0.7705243986321614]]]]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "package_ans(sgd(X, y, J, dJ, cv([0.0, 0.0]), lambda i: 0.1, 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Test 2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[-1.168945161526412], [0.5656868407680322]],\n",
       " [0.419904, 0.023688169520937184],\n",
       " [[[-0.1], [0.1]], [[-1.168945161526412], [0.5656868407680322]]]]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "package_ans(sgd(X, y, J, dJ, cv([-0.1, 0.1]), lambda i: 0.01, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "589de4b78d110c5d67d4fa6fe6e172435b70bd56bfbdc482f8885043e8186e7e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('regression': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
